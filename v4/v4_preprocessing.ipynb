{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7b2f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: ../../data/raw\n",
      "OUT_DIR: ../../data/processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# PATH ì„¤ì •\n",
    "# ============================\n",
    "RAW_DIR = \"../../data/raw\"          # ì›ë³¸ ë°ì´í„°\n",
    "OUT_DIR = \"../../data/processed\"    # ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "RAW_FILES = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"dev\": \"dev.csv\",\n",
    "    \"test\": \"test.csv\",\n",
    "}\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "def normalize_newlines(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = text.replace(\"\\\\n\", \"\\n\")\n",
    "    text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text\n",
    "\n",
    "def normalize_quotes_symbols(text: str) -> str:\n",
    "    rep = {\n",
    "        \"â€œ\": '\"', \"â€\": '\"',\n",
    "        \"â€˜\": \"'\", \"â€™\": \"'\",\n",
    "        \"ã€Œ\": '\"', \"ã€\": '\"',\n",
    "        \"ã€\": '\"', \"ã€\": '\"'\n",
    "    }\n",
    "    for k, v in rep.items():\n",
    "        text = text.replace(k, v)\n",
    "    text = re.sub(r\"[ã€ã€ã€Šã€‹â”€â”â”‚â”ƒâ•­â•®â•°â•¯]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def clean_utterance(text: str) -> str:\n",
    "    t = text.strip()\n",
    "\n",
    "    # 1) ê°ì • í‘œí˜„ ì œê±°\n",
    "    t = re.sub(r\"(ã…‹ã…‹+|ã…ã…+|ã… ã… +|ã…œã…œ+)\", \"\", t)\n",
    "\n",
    "    # 2) ë¬¼ê²° ì œê±°\n",
    "    t = re.sub(r\"~{2,}\", \"\", t)\n",
    "\n",
    "    # 3) ë§ì¤„ì„í‘œ â†’ .\n",
    "    t = re.sub(r\"\\.{2,}\", \".\", t)\n",
    "\n",
    "    # 4) ë¬¸ì¥ë¶€í˜¸ normalize\n",
    "    t = re.sub(r\"\\?{2,}\", \"?\", t)\n",
    "    t = re.sub(r\"!{2,}\", \"!\", t)\n",
    "\n",
    "    # 5) ì˜ëª»ëœ ì¡°í•© ì •ë¦¬\n",
    "    t = re.sub(r\",\\?\", \"?\", t)\n",
    "    t = re.sub(r\",\\.\", \".\", t)\n",
    "    t = re.sub(r\"\\?\\.\", \"?\", t)\n",
    "    t = re.sub(r\"!\\.\", \"!\", t)\n",
    "\n",
    "    # 6) ë°˜ë³µ ë‹¨ì–´ ì •ë¦¬\n",
    "    t = re.sub(r\"\\b(\\w+)(\\s+\\1){2,}\\b\", r\"\\1\", t)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # ğŸ”¥ 7) ë¬¸ì¥ ê²½ê³„ ë¶„ë¦¬: \"ì¢…ê²°í˜• + ê³µë°± + ì¼ë°˜ ë‹¨ì–´\" â†’ \".\" ì‚½ì…\n",
    "    # ---------------------------------------------------\n",
    "    # ì˜ˆ: \"ìˆì–´ìš” ê²°êµ­\" â†’ \"ìˆì–´ìš”. ê²°êµ­\"\n",
    "    t = re.sub(\n",
    "        r\"(ì–´ìš”|ìŠµë‹ˆë‹¤|í•©ë‹ˆë‹¤|í•´ìš”|ì˜ˆìš”|ì—ìš”|ì˜€ì–´ìš”|ì˜€ìŠµë‹ˆ ë‹¤|ì˜€ë˜|ì´ì£ |ì£ )(\\s+)([ê°€-í£A-Za-z0-9])\",\n",
    "        r\"\\1. \\3\",\n",
    "        t\n",
    "    )\n",
    "\n",
    "    # 8) ê³µë°± ì •ë¦¬\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "    # 9) ë¬¸ì¥ ë ë¬¸ì¥ë¶€í˜¸ ê°•ì œ\n",
    "    if t and t[-1] not in \".?!\":\n",
    "        t = t + \".\"\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_dialogue_v4(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if text is None else str(text)\n",
    "\n",
    "    t = normalize_newlines(text)\n",
    "    t = normalize_quotes_symbols(t)\n",
    "\n",
    "    lines = t.split(\"\\n\")\n",
    "    out_lines = []\n",
    "\n",
    "    for ln in lines:\n",
    "        stripped = ln.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "\n",
    "        # \"#PersonN#:\" í˜•íƒœ ê°ì§€\n",
    "        m = re.match(r\"^(#Person\\d+#:)\\s*(.*)$\", stripped)\n",
    "        if m:\n",
    "            tag = m.group(1)                # \"#Person1#:\"\n",
    "            utt = m.group(2)                # ë°œí™”\n",
    "            cleaned = clean_utterance(utt)\n",
    "            out_lines.append(f\"{tag} {cleaned}\")   # ê³µë°± ê°•ì œ ì‚½ì…\n",
    "        else:\n",
    "            cleaned = clean_utterance(stripped)\n",
    "            out_lines.append(cleaned)\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9acd550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing TRAIN  (../../data/raw/train.csv -> ../../data/processed/v4_train_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12457/12457 [00:02<00:00, 6133.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing DEV  (../../data/raw/dev.csv -> ../../data/processed/v4_dev_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 6698.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing TEST  (../../data/raw/test.csv -> ../../data/processed/v4_test_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 5900.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All preprocessing done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split, fname in RAW_FILES.items():\n",
    "    in_path = os.path.join(RAW_DIR, fname)\n",
    "    out_path = os.path.join(OUT_DIR, f\"v4_{split}_preprocessed.csv\")\n",
    "\n",
    "    print(f\"[INFO] Preprocessing {split.upper()}  ({in_path} -> {out_path})\")\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    df[\"dialogue\"] = [preprocess_dialogue_v4(t) for t in tqdm(df[\"dialogue\"])]\n",
    "\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[INFO] All preprocessing done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb70598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BEFORE =====\n",
      "\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”!! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”??.\n",
      "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!! ã…ã…ã…\n",
      "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”~~~ ê²°êµ­ ê²°êµ­ ê²°êµ­\n",
      "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”,?? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
      "\n",
      "\n",
      "===== AFTER (v4 preprocess) =====\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”?\n",
      "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!\n",
      "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”. ê²°êµ­.\n",
      "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "#Person1#: ì•ˆë…•í•˜ì„¸ìš”!! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”??.\n",
    "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!! ã…ã…ã…\n",
    "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”~~~ ê²°êµ­ ê²°êµ­ ê²°êµ­\n",
    "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”,?? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
    "\"\"\"\n",
    "\n",
    "print(\"===== BEFORE =====\")\n",
    "print(sample_text)\n",
    "\n",
    "print(\"\\n===== AFTER (v4 preprocess) =====\")\n",
    "print(preprocess_dialogue_v4(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562eb34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
