# ===============================================================
# General settings (KoBART Summarization)
# ===============================================================
general:
  data_dir: "../../data/processed"
  train_file: "v2_train_preprocessed.csv"
  test_file: "v2_test_preprocessed.csv"

  model_name: "digit82/kobart-summarization"
  output_dir: "../outputs/kobart_v2/"
  seed: 42

  prefix: ""   # KoBART는 prefix 없이 학습하는 것이 안정적

# ===============================================================
# Tokenizer settings
# ===============================================================
tokenizer:
  encoder_max_len: 640
  decoder_max_len: 100
  special_tokens: []

# ===============================================================
# Training settings
# ===============================================================
training:
  optim: adamw_torch
  do_train: true
  do_eval: true

  num_train_epochs: 4
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4

  learning_rate: 0.00005 # ← 반드시 추가

  warmup_ratio: 0.05
  weight_decay: 0.01
  lr_scheduler_type: cosine

  logging_steps: 100
  save_strategy: "epoch"
  save_total_limit: 1
  load_best_model_at_end: false

  fp16: true
  bf16: false
  predict_with_generate: true

# ===============================================================
# Optuna settings (2 trials)
# ===============================================================
optuna:
  use: true
  n_trials: 2
  direction: "maximize"

  search_space:
    learning_rate: [0.00003, 0.00005]
    warmup_ratio: [0.05, 0.1, 0.15]
    num_train_epochs: [3, 4]

# ===============================================================
# Inference settings
# ===============================================================
inference:
  num_beams: 5
  max_length: 100
  no_repeat_ngram_size: 3
  batch_size: 4

  remove_tokens:
    - "<pad>"

# ===============================================================
# wandb settings
# ===============================================================
wandb:
  project: "fastcampus_text_generation_with_transformer"
  entity: "milpasoomin-no"
  name: "v2_kobart"
  mode: "online"
