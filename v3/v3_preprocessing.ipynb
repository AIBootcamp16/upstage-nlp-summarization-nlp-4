{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb5f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing TRAIN  (../../data/raw/train.csv -> ../../data/processed/v3_train_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12457/12457 [00:02<00:00, 5805.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing DEV  (../../data/raw/dev.csv -> ../../data/processed/v3_dev_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 6226.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing TEST  (../../data/raw/test.csv -> ../../data/processed/v3_test_preprocessed.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 6025.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All done!\n",
      "../../data/processed/v3_train_preprocessed.csv\n",
      "../../data/processed/v3_dev_preprocessed.csv\n",
      "../../data/processed/v3_test_preprocessed.csv\n",
      "=== BEFORE SAMPLE ===\n",
      "\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”!! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”??.\n",
      "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!! ã…ã…ã…\n",
      "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”~~~ ê²°êµ­ ê²°êµ­ ê²°êµ­\n",
      "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”,?? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
      "\n",
      "\n",
      "=== AFTER SAMPLE (preprocessed) ===\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”?\n",
      "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!\n",
      "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”. ê²°êµ­.\n",
      "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 0. PATH ì„¤ì • (ëŒ€ì¥ í™˜ê²½ì— ë§ê²Œ ì¡°ì •)\n",
    "# ============================\n",
    "RAW_DIR = \"../../data/raw\"        # ğŸ”´ ì›ë³¸ train/dev/test ìœ„ì¹˜\n",
    "OUT_DIR = \"../../data/processed\"  # ğŸ”µ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì €ì¥ ìœ„ì¹˜\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "RAW_FILES = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"dev\": \"dev.csv\",\n",
    "    \"test\": \"test.csv\",\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# 1. ìœ í‹¸ í•¨ìˆ˜ë“¤\n",
    "# ============================\n",
    "def normalize_newlines(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = text.replace(\"\\\\n\", \"\\n\")\n",
    "    text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text\n",
    "\n",
    "def normalize_quotes_symbols(text: str) -> str:\n",
    "    rep = {\n",
    "        \"â€œ\": '\"', \"â€\": '\"',\n",
    "        \"â€˜\": \"'\", \"â€™\": \"'\",\n",
    "        \"ã€Œ\": '\"', \"ã€\": '\"',\n",
    "        \"ã€\": '\"', \"ã€\": '\"'\n",
    "    }\n",
    "    for k, v in rep.items():\n",
    "        text = text.replace(k, v)\n",
    "    text = re.sub(r\"[ã€ã€ã€Šã€‹â”€â”â”‚â”ƒâ•­â•®â•°â•¯]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# ìŠ¤í”¼ì»¤ íƒœê·¸: \"#PersonN#\" ì´ë©´ì„œ ë°”ë¡œ ë’¤ì— ê³µë°± ë˜ëŠ” ì½œë¡ ì´ ì˜¤ëŠ” ê²½ìš°ë§Œ \"í„´ ì‹œì‘\"ìœ¼ë¡œ ë³¸ë‹¤.\n",
    "SPEAKER_TAG = re.compile(r\"(#Person\\d+#)(?=\\s|:)\", re.I)\n",
    "\n",
    "def split_by_speaker(text: str):\n",
    "    \"\"\"\n",
    "    1) \"#PersonN#\" ì•ì— ì¤„ë°”ê¿ˆì„ ë„£ì–´ì„œ\n",
    "    2) ê° ì¤„ì˜ ë§¨ ì• \"#PersonN#\"ì„ í™”ìë¡œ ì¸ì‹\n",
    "    3) ë¬¸ì¥ ì¤‘ê°„ì˜ \"#Person1#ë‹˜\" ê°™ì€ ê±´ ê±´ë“œë¦¬ì§€ ì•ŠìŒ\n",
    "    \"\"\"\n",
    "    # \"#PersonN#\" ì•ì— newline ì‚½ì… (í„´ ì‹œì‘ í›„ë³´ë§Œ)\n",
    "    text = SPEAKER_TAG.sub(r\"\\n\\1\", text).strip()\n",
    "\n",
    "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "    segments = []\n",
    "    current_spk = None\n",
    "    current_utt = []\n",
    "\n",
    "    for ln in lines:\n",
    "        m = SPEAKER_TAG.match(ln)\n",
    "        if m:\n",
    "            # ìƒˆë¡œìš´ í™”ì ë“±ì¥\n",
    "            if current_spk is not None and current_utt:\n",
    "                segments.append((current_spk, \" \".join(current_utt).strip()))\n",
    "            current_spk = m.group(1)  # \"#Person1#\"\n",
    "            rest = ln[m.end():].lstrip(\" :\")\n",
    "            current_utt = [rest] if rest else []\n",
    "        else:\n",
    "            # ì´ì „ í™”ìì˜ ë°œí™” ì´ì–´ë¶™ì´ê¸°\n",
    "            if current_spk is None:\n",
    "                # ë§¨ ì²˜ìŒì— speaker ì—†ì´ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ë©´ ê·¸ëƒ¥ í•˜ë‚˜ì˜ utteranceë¡œ ì·¨ê¸‰\n",
    "                current_spk = \"\"\n",
    "                current_utt = [ln]\n",
    "            else:\n",
    "                current_utt.append(ln)\n",
    "\n",
    "    if current_spk is not None and current_utt:\n",
    "        segments.append((current_spk, \" \".join(current_utt).strip()))\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "def clean_utterance(text: str) -> str:\n",
    "    t = text.strip()\n",
    "\n",
    "    # 1) ê°ì • í‘œí˜„ ì œê±°\n",
    "    t = re.sub(r\"(ã…‹ã…‹+|ã…ã…+|ã… ã… +|ã…œã…œ+)\", \"\", t)\n",
    "\n",
    "    # 2) ë¬¼ê²° ì œê±° ë˜ëŠ” \".\" í†µì¼\n",
    "    t = re.sub(r\"~{2,}\", \".\", t)\n",
    "\n",
    "    # 3) ë§ì¤„ì„í‘œ \".\" í•˜ë‚˜ë¡œ í†µì¼\n",
    "    t = re.sub(r\"\\.{2,}\", \".\", t)\n",
    "\n",
    "    # 4) ë°˜ë³µ ë‹¨ì–´ 3íšŒ ì´ìƒ ì œê±°\n",
    "    t = re.sub(r\"\\b(\\w+)(\\s+\\1){2,}\\b\", r\"\\1\", t)\n",
    "\n",
    "    # 5) ë¬¸ì¥ë¶€í˜¸ ì¡°í•© ì •ë¦¬\n",
    "    t = re.sub(r\",\\?\", \"?\", t)\n",
    "    t = re.sub(r\"\\?+\", \"?\", t)\n",
    "    t = re.sub(r\"!+\", \"!\", t)\n",
    "    t = re.sub(r\"\\?\\.\",\"?\", t)\n",
    "    t = re.sub(r\"!\\.\",\"!\", t)\n",
    "\n",
    "    # 6) ê³µë°± ì •ë¦¬\n",
    "    t = re.sub(r\"\\s+([?.!,])\", r\"\\1\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 7) ë¬¸ì¥ ë ë§ˆì¹¨í‘œ ë³´ì • (í•µì‹¬)\n",
    "    # --------------------------------------------\n",
    "    # ëì´ .,?,! ë¡œ ì•ˆ ëë‚˜ë©´ \".\" ì¶”ê°€\n",
    "    if t and t[-1] not in \".?!\":\n",
    "        t = t + \".\"\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def preprocess_dialogue(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if text is None else str(text)\n",
    "\n",
    "    t = normalize_newlines(text)\n",
    "    t = normalize_quotes_symbols(t)\n",
    "\n",
    "    segments = split_by_speaker(t)\n",
    "\n",
    "    # ìŠ¤í”¼ì»¤ íƒœê·¸ë¥¼ í•˜ë‚˜ë„ ëª» ì°¾ìœ¼ë©´ ê·¸ëƒ¥ í´ë¦°ì—…ë§Œ í•´ì„œ ë°˜í™˜\n",
    "    if not segments:\n",
    "        return clean_utterance(t)\n",
    "\n",
    "    lines = []\n",
    "    for spk, utt in segments:\n",
    "        cu = clean_utterance(utt)\n",
    "        if not cu:\n",
    "            continue\n",
    "        if spk:\n",
    "            lines.append(f\"{spk}: {cu}\")\n",
    "        else:\n",
    "            lines.append(cu)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ============================\n",
    "# 2. ì‹¤ì œ ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "# ============================\n",
    "for split, fname in RAW_FILES.items():\n",
    "    in_path = os.path.join(RAW_DIR, fname)\n",
    "    out_path = os.path.join(OUT_DIR, f\"v3_{split}_preprocessed.csv\")\n",
    "\n",
    "    print(f\"[INFO] Preprocessing {split.upper()}  ({in_path} -> {out_path})\")\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # ì›ë³¸ì€ 'dialogue' ì»¬ëŸ¼ ê¸°ì¤€ (ëŒ€íšŒ í¬ë§·)\n",
    "    df[\"dialogue\"] = [preprocess_dialogue(t) for t in tqdm(df[\"dialogue\"])]\n",
    "\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[INFO] All done!\")\n",
    "print(os.path.join(OUT_DIR, \"v3_train_preprocessed.csv\"))\n",
    "print(os.path.join(OUT_DIR, \"v3_dev_preprocessed.csv\"))\n",
    "print(os.path.join(OUT_DIR, \"v3_test_preprocessed.csv\"))\n",
    "\n",
    "# ============================\n",
    "# 3. ìƒ˜í”Œ í™•ì¸\n",
    "# ============================\n",
    "sample = \"\"\"\n",
    "#Person1#: ì•ˆë…•í•˜ì„¸ìš”!! í”¼ì ì£¼ë¬¸í•˜ì‹¤ë˜ìš”??.\n",
    "#Person2#: ë„¤, #Person1#ë‹˜. í˜í¼ë¡œë‹ˆë‘ ì˜¬ë¦¬ë¸Œ ì¶”ê°€ìš”!! ã…ã…ã…\n",
    "#Person1#: ëŒ€í˜• í”¼ì í• ì¸ ìˆì–´ìš”~~~ ê²°êµ­ ê²°êµ­ ê²°êµ­\n",
    "#Person2#: ì˜¤ ê·¸ëŸ°ê°€ìš”,?? ê·¸ëŸ¼ ëŒ€í˜• ì£¼ì„¸ìš”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== BEFORE SAMPLE ===\")\n",
    "print(sample)\n",
    "print(\"\\n=== AFTER SAMPLE (preprocessed) ===\")\n",
    "print(preprocess_dialogue(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507f77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
